{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para hacer predicciones con el modelo cargado, podrías hacer lo siguiente:\n",
    "\n",
    "\n",
    "se importan las bibliotecas necesarias para trabajar con los modelos de transformers, numpy y TensorFlow.\n",
    "\n",
    "El código carga un modelo previamente guardado utilizando la clase TFCamembertForSequenceClassification. Este modelo ha sido entrenado para clasificar secuencias de texto en diferentes categorías. Necesitarás proporcionar la ruta al modelo guardado en la línea loaded_model = TFCamembertForSequenceClassification.from_pretrained(\"path_to_save_model\").\n",
    "\n",
    "Luego, se carga el tokenizador correspondiente al modelo Camembert utilizando la clase CamembertTokenizer. El tokenizador se utiliza para convertir el texto en una representación numérica que el modelo pueda entender. En este caso, se carga el tokenizador base \"camembert-base\".\n",
    "\n",
    "A continuación, se define un ejemplo de entrada de texto en la variable text. Aquí es donde debes proporcionar el texto que deseas clasificar.\n",
    "\n",
    "El código codifica la entrada de texto utilizando el tokenizador. La función encode_plus toma el texto y lo convierte en una representación numérica adecuada para el modelo. Los resultados se almacenan en la variable inputs.\n",
    "\n",
    "Luego, se realiza la predicción utilizando el modelo cargado. Se pasa la entrada codificada inputs['input_ids'] al modelo y se obtienen las predicciones.\n",
    "\n",
    "Para encontrar la clase con la mayor probabilidad, se utiliza la función argmax de la biblioteca NumPy para obtener el índice de la clase con el valor máximo en el arreglo de predicciones.\n",
    "\n",
    "Finalmente, se imprime el sentimiento predicho utilizando la lista de sentimientos proporcionada en sentiments. El índice predicho se utiliza para acceder al sentimiento correspondiente en la lista y se imprime en la consola."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "All model checkpoint layers were used when initializing TFCamembertForSequenceClassification.\n",
      "\n",
      "All the layers of TFCamembertForSequenceClassification were initialized from the model checkpoint at d:\\Python Code\\Project\\analyzer\\models\\path_to_save_model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFCamembertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le sentiment prédit pour le texte 'j'ai enfin trouvé le cadeau parfait' est: joie\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from transformers import CamembertTokenizer, TFCamembertForSequenceClassification\n",
    "\n",
    "# Definir el directorio del modelo guardado\n",
    "model_base_dir = os.path.abspath(os.path.join(os.getcwd(), '..', 'models'))\n",
    "model_dir = os.path.join(model_base_dir, 'path_to_save_model')\n",
    "\n",
    "# Cargar el modelo y el tokenizador\n",
    "tokenizer = CamembertTokenizer.from_pretrained(model_dir)\n",
    "model = TFCamembertForSequenceClassification.from_pretrained(model_dir)\n",
    "\n",
    "# Función para predecir el sentimiento de un nuevo texto\n",
    "def predict_sentiment(text):\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=64,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='tf',\n",
    "    )\n",
    "\n",
    "    input_id = encoded_dict['input_ids']\n",
    "    attention_mask = encoded_dict['attention_mask']\n",
    "\n",
    "    # Realizar la predicción\n",
    "    outputs = model(input_id, attention_mask=attention_mask)\n",
    "    logits = outputs.logits\n",
    "\n",
    "    # Obtener la etiqueta predicha\n",
    "    predicted_label = tf.argmax(logits, axis=1).numpy()[0]\n",
    "\n",
    "    return predicted_label\n",
    "\n",
    "# Mapear etiquetas a sentimientos\n",
    "label_to_sentiment = {\n",
    "    0: 'frustration',\n",
    "    1: 'tristesse',\n",
    "    2: 'colere',\n",
    "    3: 'joie',\n",
    "    4: 'neutre'\n",
    "}\n",
    "\n",
    "# Predicción para un nuevo texto ingresado por el usuario\n",
    "new_text = \"j'ai enfin trouvé le cadeau parfait\"\n",
    "predicted_label = predict_sentiment(new_text)\n",
    "predicted_sentiment = label_to_sentiment[predicted_label]\n",
    "\n",
    "print(f\"Le sentiment prédit pour le texte '{new_text}' est: {predicted_sentiment}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
